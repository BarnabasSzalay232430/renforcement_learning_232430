{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a6f00c-03db-49e6-a0b5-2f0d6dc64721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 14:46:22.920011: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-08 14:46:22.920086: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-08 14:46:22.921631: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 14:46:22.930053: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from patchify import patchify, unpatchify\n",
    "from tensorflow.keras import backend as K\n",
    "from skimage.measure import label\n",
    "\n",
    "def f1(y_true, y_pred, threshold=0.3):\n",
    "    y_pred = tf.cast(y_pred > threshold, tf.float32)\n",
    "    TP = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    Positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
    "    Pred_Positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    precision = TP / (Pred_Positives + tf.keras.backend.epsilon())\n",
    "    recall = TP / (Positives + tf.keras.backend.epsilon())\n",
    "    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
    "    \n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def f1_metric(y_true, y_pred):\n",
    "    return f1(y_true, y_pred, threshold=0.3)\n",
    "\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Weighted binary cross-entropy to address class imbalance.\n",
    "    \"\"\"\n",
    "    # Define weights for foreground (root, shoot, seed) and background\n",
    "    weight_foreground = 10.0\n",
    "    weight_background = 1.0\n",
    "\n",
    "    # Compute weighted binary cross-entropy\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    weights = tf.where(y_true == 1, weight_foreground, weight_background)\n",
    "    loss = K.binary_crossentropy(y_true, y_pred)\n",
    "    weighted_loss = loss * weights\n",
    "    return K.mean(weighted_loss)\n",
    "def dice_loss(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2. * intersection + 1e-7) / (union + 1e-7)\n",
    "    return 1 - dice\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return 0.5 * dice_loss(y_true, y_pred) + 0.5 * weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6fc810e-99cf-4b09-ac91-c8df749c3f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 14:46:27.903936: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-01-08 14:46:27.904414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15068 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "INFO: Processing image: test_image_1.png\n",
      "2025-01-08 14:46:34.978449: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "INFO: Extracted Root Tip Coordinates for test_image_1.png: [array([ 6.89359458, 43.1754469 ,  0.114     ]), array([16.52511592, 62.63902066,  0.114     ]), array([23.2015114 , 54.59262704,  0.114     ]), array([76.12015423, 39.47845524,  0.114     ]), array([1.25864773e+02, 4.50239427e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_10.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_10.png: [array([14.68959417, 90.18015252,  0.114     ]), array([3.22199730e+01, 1.15905179e+02, 1.14000000e-01]), array([ 71.46228896, 106.99003437,   0.114     ]), array([107.75607023,  96.67854135,   0.114     ]), array([1.35525906e+02, 8.86763931e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_11.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_11.png: [array([  4.39806105, 105.43256928,   0.114     ]), array([ 34.59112504, 111.2864898 ,   0.114     ]), array([ 69.98619119, 104.03622127,   0.114     ]), array([102.3780396 , 113.81065736,   0.114     ]), array([1.14980828e+02, 1.10373493e+02, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_12.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_12.png: [array([24.01768567, 76.72747278,  0.114     ]), array([45.13991583, 80.43449284,  0.114     ]), array([74.0891653 , 71.62360458,  0.114     ]), array([93.5494941 , 73.55770201,  0.114     ]), array([1.24857571e+02, 7.45784756e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_13.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_13.png: [array([ 18.76393299, 100.11570569,   0.114     ]), array([49.26786437, 88.73009882,  0.114     ]), array([70.28287509, 83.95029216,  0.114     ]), array([104.53948695,  95.87295596,   0.114     ]), array([1.23785377e+02, 1.04197338e+02, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_14.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_14.png: [array([ 6.16781435, 99.41753169,  0.114     ]), array([ 6.54321657, 75.35738131,  0.114     ]), array([1.31605784e+02, 1.39717744e+01, 1.14000000e-01]), array([1.32678361e+02, 9.67531901e+00, 1.14000000e-01]), array([1.41098097e+02, 2.88482513e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_15.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_15.png: [array([3.16459662e+00, 1.22618391e+02, 1.14000000e-01]), array([7.88393877e+00, 1.23370271e+02, 1.14000000e-01]), array([ 9.81457875, 76.64631794,  0.114     ]), array([19.68229415, 90.71720945,  0.114     ]), array([1.47372677e+02, 1.34379938e+02, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_16.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_16.png: [array([1.39926678e+01, 1.34057704e+02, 1.14000000e-01]), array([22.30217459, 46.78595274,  0.114     ]), array([50.92976573, 46.46371858,  0.114     ]), array([103.73534114,  49.47123738,   0.114     ]), array([1.32362932e+02, 4.70544812e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_17.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_17.png: [array([16.02983721, 59.48177077,  0.114     ]), array([45.51518388, 62.54409169,  0.114     ]), array([73.76750697, 66.3585616 ,  0.114     ]), array([104.96836472,  64.74681375,   0.114     ]), array([1.24482303e+02, 6.22754670e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_18.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_18.png: [array([ 13.83674535, 113.81065736,   0.114     ]), array([16.3036742 , 58.17155961,  0.114     ]), array([50.5725337 , 83.25211815,  0.114     ]), array([106.93649508,  96.73224705,   0.114     ]), array([1.34448115e+02, 9.67322470e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_2.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_2.png: [array([ 6.47567453, 82.39160692,  0.114     ]), array([49.03735813, 32.8964753 ,  0.114     ]), array([67.9778516 , 72.33030148,  0.114     ]), array([100.74272823, 101.86510133,   0.114     ]), array([1.20064209e+02, 9.04514699e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_3.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_3.png: [array([20.7785484 , 36.16406298,  0.114     ]), array([49.59735992, 29.43224973,  0.114     ]), array([76.01004676, 31.49522476,  0.114     ]), array([103.35237268,  33.66677742,   0.114     ]), array([1.32116500e+02, 3.15495136e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_4.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_4.png: [array([22.09756448, 44.34204331,  0.114     ]), array([50.96260631, 43.42179791,  0.114     ]), array([76.33546917, 37.84619343,  0.114     ]), array([99.79854665, 43.09700541,  0.114     ]), array([1.31992072e+02, 3.41110798e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_5.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_5.png: [array([21.76957874, 43.94728139,  0.114     ]), array([47.24127685, 40.91697835,  0.114     ]), array([74.56348295, 31.98840693,  0.114     ]), array([101.5047021,  39.5641645,   0.114    ]), array([1.33616458e+02, 3.87524762e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_6.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_6.png: [array([21.41178197, 44.70937794,  0.114     ]), array([43.47861814, 52.90105967,  0.114     ]), array([71.538916  , 52.90105967,  0.114     ]), array([100.30753206,  51.43632188,   0.114     ]), array([1.28749232e+02, 4.19969005e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_7.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_7.png: [array([20.96831645, 50.062     ,  0.114     ]), array([47.22103976, 37.73843865,  0.114     ]), array([75.43454739, 32.25526819,  0.114     ]), array([105.17310948,  49.68197828,   0.114     ]), array([1.31752630e+02, 5.38622172e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_8.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_8.png: [array([9.48275000e+00, 1.33317058e+02, 1.14000000e-01]), array([3.07400174e+01, 1.37002029e+02, 1.14000000e-01]), array([7.51622558e+01, 1.29523705e+02, 1.14000000e-01]), array([8.93337674e+01, 1.19390035e+02, 1.14000000e-01]), array([1.31139727e+02, 6.31942254e+01, 1.14000000e-01])]\n",
      "INFO: Processing image: test_image_9.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_9.png: [array([23.48158846, 58.22526531,  0.114     ]), array([47.60596301, 55.37886359,  0.114     ]), array([75.59023749, 62.09207519,  0.114     ]), array([106.09416887,  50.92129108,   0.114     ]), array([1.31934055e+02, 6.07494329e+01, 1.14000000e-01])]\n",
      "INFO: All Extracted Root Tip Coordinates:\n",
      "INFO: test_image_1.png: [array([ 6.89359458, 43.1754469 ,  0.114     ]), array([16.52511592, 62.63902066,  0.114     ]), array([23.2015114 , 54.59262704,  0.114     ]), array([76.12015423, 39.47845524,  0.114     ]), array([1.25864773e+02, 4.50239427e+01, 1.14000000e-01])]\n",
      "INFO: test_image_10.png: [array([14.68959417, 90.18015252,  0.114     ]), array([3.22199730e+01, 1.15905179e+02, 1.14000000e-01]), array([ 71.46228896, 106.99003437,   0.114     ]), array([107.75607023,  96.67854135,   0.114     ]), array([1.35525906e+02, 8.86763931e+01, 1.14000000e-01])]\n",
      "INFO: test_image_11.png: [array([  4.39806105, 105.43256928,   0.114     ]), array([ 34.59112504, 111.2864898 ,   0.114     ]), array([ 69.98619119, 104.03622127,   0.114     ]), array([102.3780396 , 113.81065736,   0.114     ]), array([1.14980828e+02, 1.10373493e+02, 1.14000000e-01])]\n",
      "INFO: test_image_12.png: [array([24.01768567, 76.72747278,  0.114     ]), array([45.13991583, 80.43449284,  0.114     ]), array([74.0891653 , 71.62360458,  0.114     ]), array([93.5494941 , 73.55770201,  0.114     ]), array([1.24857571e+02, 7.45784756e+01, 1.14000000e-01])]\n",
      "INFO: test_image_13.png: [array([ 18.76393299, 100.11570569,   0.114     ]), array([49.26786437, 88.73009882,  0.114     ]), array([70.28287509, 83.95029216,  0.114     ]), array([104.53948695,  95.87295596,   0.114     ]), array([1.23785377e+02, 1.04197338e+02, 1.14000000e-01])]\n",
      "INFO: test_image_14.png: [array([ 6.16781435, 99.41753169,  0.114     ]), array([ 6.54321657, 75.35738131,  0.114     ]), array([1.31605784e+02, 1.39717744e+01, 1.14000000e-01]), array([1.32678361e+02, 9.67531901e+00, 1.14000000e-01]), array([1.41098097e+02, 2.88482513e+01, 1.14000000e-01])]\n",
      "INFO: test_image_15.png: [array([3.16459662e+00, 1.22618391e+02, 1.14000000e-01]), array([7.88393877e+00, 1.23370271e+02, 1.14000000e-01]), array([ 9.81457875, 76.64631794,  0.114     ]), array([19.68229415, 90.71720945,  0.114     ]), array([1.47372677e+02, 1.34379938e+02, 1.14000000e-01])]\n",
      "INFO: test_image_16.png: [array([1.39926678e+01, 1.34057704e+02, 1.14000000e-01]), array([22.30217459, 46.78595274,  0.114     ]), array([50.92976573, 46.46371858,  0.114     ]), array([103.73534114,  49.47123738,   0.114     ]), array([1.32362932e+02, 4.70544812e+01, 1.14000000e-01])]\n",
      "INFO: test_image_17.png: [array([16.02983721, 59.48177077,  0.114     ]), array([45.51518388, 62.54409169,  0.114     ]), array([73.76750697, 66.3585616 ,  0.114     ]), array([104.96836472,  64.74681375,   0.114     ]), array([1.24482303e+02, 6.22754670e+01, 1.14000000e-01])]\n",
      "INFO: test_image_18.png: [array([ 13.83674535, 113.81065736,   0.114     ]), array([16.3036742 , 58.17155961,  0.114     ]), array([50.5725337 , 83.25211815,  0.114     ]), array([106.93649508,  96.73224705,   0.114     ]), array([1.34448115e+02, 9.67322470e+01, 1.14000000e-01])]\n",
      "INFO: test_image_2.png: [array([ 6.47567453, 82.39160692,  0.114     ]), array([49.03735813, 32.8964753 ,  0.114     ]), array([67.9778516 , 72.33030148,  0.114     ]), array([100.74272823, 101.86510133,   0.114     ]), array([1.20064209e+02, 9.04514699e+01, 1.14000000e-01])]\n",
      "INFO: test_image_3.png: [array([20.7785484 , 36.16406298,  0.114     ]), array([49.59735992, 29.43224973,  0.114     ]), array([76.01004676, 31.49522476,  0.114     ]), array([103.35237268,  33.66677742,   0.114     ]), array([1.32116500e+02, 3.15495136e+01, 1.14000000e-01])]\n",
      "INFO: test_image_4.png: [array([22.09756448, 44.34204331,  0.114     ]), array([50.96260631, 43.42179791,  0.114     ]), array([76.33546917, 37.84619343,  0.114     ]), array([99.79854665, 43.09700541,  0.114     ]), array([1.31992072e+02, 3.41110798e+01, 1.14000000e-01])]\n",
      "INFO: test_image_5.png: [array([21.76957874, 43.94728139,  0.114     ]), array([47.24127685, 40.91697835,  0.114     ]), array([74.56348295, 31.98840693,  0.114     ]), array([101.5047021,  39.5641645,   0.114    ]), array([1.33616458e+02, 3.87524762e+01, 1.14000000e-01])]\n",
      "INFO: test_image_6.png: [array([21.41178197, 44.70937794,  0.114     ]), array([43.47861814, 52.90105967,  0.114     ]), array([71.538916  , 52.90105967,  0.114     ]), array([100.30753206,  51.43632188,   0.114     ]), array([1.28749232e+02, 4.19969005e+01, 1.14000000e-01])]\n",
      "INFO: test_image_7.png: [array([20.96831645, 50.062     ,  0.114     ]), array([47.22103976, 37.73843865,  0.114     ]), array([75.43454739, 32.25526819,  0.114     ]), array([105.17310948,  49.68197828,   0.114     ]), array([1.31752630e+02, 5.38622172e+01, 1.14000000e-01])]\n",
      "INFO: test_image_8.png: [array([9.48275000e+00, 1.33317058e+02, 1.14000000e-01]), array([3.07400174e+01, 1.37002029e+02, 1.14000000e-01]), array([7.51622558e+01, 1.29523705e+02, 1.14000000e-01]), array([8.93337674e+01, 1.19390035e+02, 1.14000000e-01]), array([1.31139727e+02, 6.31942254e+01, 1.14000000e-01])]\n",
      "INFO: test_image_9.png: [array([23.48158846, 58.22526531,  0.114     ]), array([47.60596301, 55.37886359,  0.114     ]), array([75.59023749, 62.09207519,  0.114     ]), array([106.09416887,  50.92129108,   0.114     ]), array([1.31934055e+02, 6.07494329e+01, 1.14000000e-01])]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"pipeline_log.txt\"), logging.StreamHandler()],\n",
    ")\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess the input image.\"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    return image\n",
    "\n",
    "def extract_petri_dish(image):\n",
    "    \"\"\"Extract the largest contour assumed to be the Petri dish.\"\"\"\n",
    "    _, thresholded = cv2.threshold(image, 57, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        logging.warning(\"No contours detected for Petri dish.\")\n",
    "        return image, np.ones_like(image)\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    return cropped_image\n",
    "\n",
    "def predict_root_mask(image, model, patch_size=128, stride=64):\n",
    "    \"\"\"Predict root mask using a patch-based model.\"\"\"\n",
    "    h, w = image.shape\n",
    "    patches = []\n",
    "    positions = []\n",
    "    for y in range(0, h - patch_size + 1, stride):\n",
    "        for x in range(0, w - patch_size + 1, stride):\n",
    "            patch = image[y:y+patch_size, x:x+patch_size]\n",
    "            patch_rgb = np.stack([patch]*3, axis=-1)\n",
    "            patches.append(patch_rgb)\n",
    "            positions.append((y, x))\n",
    "\n",
    "    patches = np.array(patches) / 255.0\n",
    "    predictions = model.predict(patches, verbose=0)\n",
    "\n",
    "    reconstructed = np.zeros((h, w), dtype=np.float32)\n",
    "    counts = np.zeros((h, w), dtype=np.float32)\n",
    "    for pred, (y, x) in zip(predictions, positions):\n",
    "        pred = pred[..., 0]\n",
    "        reconstructed[y:y+patch_size, x:x+patch_size] += pred\n",
    "        counts[y:y+patch_size, x:x+patch_size] += 1\n",
    "    return (reconstructed / np.maximum(counts, 1) > 0.3).astype(np.uint8)\n",
    "\n",
    "def connect_roots(mask):\n",
    "    \"\"\"Dilate the mask to connect fragmented roots.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "    return cv2.dilate(mask, kernel, iterations=27)\n",
    "\n",
    "def filter_and_select_largest_objects(mask, min_area=500, max_objects=5):\n",
    "    \"\"\"Filter and retain the largest root components.\"\"\"\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    valid_objects = [(i, stats[i, cv2.CC_STAT_AREA]) for i in range(1, num_labels) if stats[i, cv2.CC_STAT_AREA] >= min_area]\n",
    "    largest_objects = sorted(valid_objects, key=lambda x: x[1], reverse=True)[:max_objects]\n",
    "\n",
    "    filtered_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for obj_id, _ in largest_objects:\n",
    "        filtered_mask[labels == obj_id] = 255\n",
    "    return filtered_mask, largest_objects\n",
    "\n",
    "def measure_bounding_boxes(filtered_mask):\n",
    "    \"\"\"Measure roots with bounding boxes.\"\"\"\n",
    "    contours, _ = cv2.findContours(filtered_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    bounding_boxes = sorted(bounding_boxes, key=lambda b: b[0])\n",
    "    return bounding_boxes\n",
    "\n",
    "def find_lowest_point(mask, bounding_box):\n",
    "    \"\"\"Find the lowest point in a bounding box.\"\"\"\n",
    "    x, y, w, h = bounding_box\n",
    "    roi = mask[y:y+h, x:x+w]\n",
    "    coordinates = np.column_stack(np.where(roi > 0))\n",
    "    if len(coordinates) == 0:\n",
    "        return None\n",
    "    lowest_local = coordinates[np.argmax(coordinates[:, 0])]\n",
    "    return lowest_local + [y, x]\n",
    "\n",
    "def convert_to_mm(pixel_coords, image_shape, plate_size_mm=150):\n",
    "    \"\"\"Convert pixel coordinates to mm-space.\"\"\"\n",
    "    h, w = image_shape\n",
    "    conversion_factor_x = plate_size_mm / w\n",
    "    conversion_factor_y = plate_size_mm / h\n",
    "    return np.array([pixel_coords[1] * conversion_factor_x, pixel_coords[0] * conversion_factor_y])\n",
    "\n",
    "# Directory containing images\n",
    "input_dir = \"kaggle_test\"\n",
    "model_path = \"232430_unet_model_128px_v7md.keras\"\n",
    "plate_position_robot = np.array([0.10775, 0.088 - 0.026, 0.057])  # Adjust based on your setup\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Process all images in the directory\n",
    "all_root_tip_coords = {}\n",
    "\n",
    "for image_name in sorted(os.listdir(input_dir)):\n",
    "    if not image_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(input_dir, image_name)\n",
    "    logging.info(f\"Processing image: {image_name}\")\n",
    "\n",
    "    try:\n",
    "        # Process the image\n",
    "        image = preprocess_image(image_path)\n",
    "        petri_dish = extract_petri_dish(image)\n",
    "        predicted_mask = predict_root_mask(petri_dish, model)\n",
    "        connected_mask = connect_roots(predicted_mask)\n",
    "\n",
    "        # Filter and select largest components\n",
    "        filtered_mask, _ = filter_and_select_largest_objects(connected_mask, min_area=500, max_objects=5)\n",
    "        bounding_boxes = measure_bounding_boxes(filtered_mask)\n",
    "\n",
    "        # Extract coordinates in robot space\n",
    "        root_tip_coords = []\n",
    "        for box in bounding_boxes:\n",
    "            point = find_lowest_point(filtered_mask, box)\n",
    "            if point is not None:\n",
    "                mm_coords = convert_to_mm(point, petri_dish.shape)\n",
    "                robot_coords = np.append(mm_coords, 0.057) + plate_position_robot\n",
    "                root_tip_coords.append(robot_coords)\n",
    "\n",
    "        all_root_tip_coords[image_name] = root_tip_coords\n",
    "        logging.info(f\"Extracted Root Tip Coordinates for {image_name}: {root_tip_coords}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing image {image_name}: {e}\")\n",
    "\n",
    "# Log all extracted root tip coordinates\n",
    "logging.info(\"All Extracted Root Tip Coordinates:\")\n",
    "for img_name, coords in all_root_tip_coords.items():\n",
    "    logging.info(f\"{img_name}: {coords}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce6b934e-0822-4762-8ed6-f50deab651a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting Optimized PID Controller Test with OT2Env\n",
      "pybullet build time: Nov 28 2023 23:48:36\n",
      "INFO: Processing root tips for image_1.png\n",
      "INFO: Root Tip 1: Target Position: [0.12, 0.05, 0.057]\n",
      "INFO: Epoch: 1\n",
      "INFO: Current Position: X=0.0730, Y=0.0895, Z=0.1195\n",
      "INFO: Errors: X=0.0470, Y=0.0395, Z=0.0625\n",
      "INFO: Euclidean Error: 0.0876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/y2b/renforcement_learning_232430\n",
      "Processing image_1.png...\n",
      "Root Tip 1: Target Position: [0.12, 0.05, 0.057]\n",
      "Environment reset. Initial observation: [ 0.073       0.0895      0.1195     -0.28448522  0.19613717 -0.0504676 ]\n",
      "Epoch 1: Euclidean Error = 0.0876\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PIDController' object has no attribute 'setpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m     pid_z\u001b[38;5;241m.\u001b[39mKi, pid_z\u001b[38;5;241m.\u001b[39mKd \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.08\u001b[39m, \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Compute control actions with action saturation\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m control_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\u001b[43mpid_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_position\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    100\u001b[0m control_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(pid_y\u001b[38;5;241m.\u001b[39mcompute(current_position[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    101\u001b[0m control_z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(pid_z\u001b[38;5;241m.\u001b[39mcompute(current_position[\u001b[38;5;241m2\u001b[39m]), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/home/y2b/renforcement_learning_232430/pid_class.py:12\u001b[0m, in \u001b[0;36mPIDController.compute\u001b[0;34m(self, current_value)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, current_value):\n\u001b[0;32m---> 12\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetpoint\u001b[49m \u001b[38;5;241m-\u001b[39m current_value\n\u001b[1;32m     13\u001b[0m     proportional \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mKp \u001b[38;5;241m*\u001b[39m error\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Update integral term with anti-windup\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PIDController' object has no attribute 'setpoint'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "from pid_class import PIDController\n",
    "from ot2_class import OT2Env\n",
    "\n",
    "# Logging configuration\n",
    "log_file = \"adaptive_pid_optimized_ot2.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler(log_file)],\n",
    ")\n",
    "\n",
    "logging.info(\"Starting Optimized PID Controller Test with OT2Env\")\n",
    "\n",
    "# Initialize the OT2 environment\n",
    "env = OT2Env()\n",
    "\n",
    "# Initialize PID parameters\n",
    "pid_x = PIDController(Kp=10, Ki=0.1, Kd=2, dt=0.5, integral_limit=5.0)\n",
    "pid_y = PIDController(Kp=10, Ki=0.1, Kd=2, dt=0.5, integral_limit=5.0)\n",
    "pid_z = PIDController(Kp=10, Ki=0.1, Kd=2, dt=0.5, integral_limit=1.0)\n",
    "\n",
    "# Example root tip coordinates (replace with actual coordinates)\n",
    "root_tip_coords = {\n",
    "    \"image_1.png\": [[0.12, 0.05, 0.057], [0.15, 0.08, 0.057]],\n",
    "    \"image_2.png\": [[0.11, 0.07, 0.057], [0.14, 0.09, 0.057]],\n",
    "}\n",
    "\n",
    "if not root_tip_coords:\n",
    "    logging.error(\"No root tip coordinates provided.\")\n",
    "    print(\"No root tip coordinates found. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "for image_name, coordinates in root_tip_coords.items():\n",
    "    logging.info(f\"Processing root tips for {image_name}\")\n",
    "    print(f\"Processing {image_name}...\")\n",
    "\n",
    "    for idx, target_position in enumerate(coordinates):\n",
    "        logging.info(f\"Root Tip {idx + 1}: Target Position: {target_position}\")\n",
    "        print(f\"Root Tip {idx + 1}: Target Position: {target_position}\")\n",
    "\n",
    "        try:\n",
    "            observation, info = env.reset()\n",
    "            print(f\"Environment reset. Initial observation: {observation}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Environment reset failed: {e}\")\n",
    "            print(f\"Failed to reset environment for {image_name}, Root Tip {idx + 1}.\")\n",
    "            continue\n",
    "\n",
    "        # Initialize loop variables\n",
    "        terminated = False\n",
    "        epoch = 0\n",
    "        all_error = 0\n",
    "        recent_errors = []\n",
    "\n",
    "        # Simulation loop\n",
    "        while not terminated and epoch < 200:\n",
    "            epoch += 1\n",
    "\n",
    "            # Current pipette position\n",
    "            current_position = observation[:3]\n",
    "\n",
    "            # Compute individual axis errors\n",
    "            error_x = abs(target_position[0] - current_position[0])\n",
    "            error_y = abs(target_position[1] - current_position[1])\n",
    "            error_z = abs(target_position[2] - current_position[2])\n",
    "            error = np.linalg.norm(target_position - current_position)\n",
    "            all_error += error\n",
    "\n",
    "            # Log errors and coordinates\n",
    "            logging.info(f\"Epoch: {epoch}\")\n",
    "            logging.info(f\"Current Position: X={current_position[0]:.4f}, Y={current_position[1]:.4f}, Z={current_position[2]:.4f}\")\n",
    "            logging.info(f\"Errors: X={error_x:.4f}, Y={error_y:.4f}, Z={error_z:.4f}\")\n",
    "            logging.info(f\"Euclidean Error: {error:.4f}\")\n",
    "            print(f\"Epoch {epoch}: Euclidean Error = {error:.4f}\")\n",
    "\n",
    "            # Success criterion\n",
    "            if error <= 0.005:\n",
    "                logging.info(f\"Root Tip {idx + 1}: Target reached successfully in {epoch} epochs. Final Error: {error:.4f}\")\n",
    "                print(f\"Root Tip {idx + 1} reached in {epoch} epochs with final error {error:.4f}\")\n",
    "                break\n",
    "\n",
    "            # Adjust PID parameters dynamically\n",
    "            if error > 0.1:\n",
    "                pid_x.Ki, pid_x.Kd = 0.20, 3\n",
    "                pid_y.Ki, pid_y.Kd = 0.20, 3\n",
    "                pid_z.Ki, pid_z.Kd = 0.18, 2.8\n",
    "            elif 0.05 < error <= 0.1:\n",
    "                pid_x.Ki, pid_x.Kd = 0.12, 1.8\n",
    "                pid_y.Ki, pid_y.Kd = 0.12, 1.8\n",
    "                pid_z.Ki, pid_z.Kd = 0.1, 1.5\n",
    "            else:\n",
    "                pid_x.Ki, pid_x.Kd = 0.1, 1.2\n",
    "                pid_y.Ki, pid_y.Kd = 0.1, 1.2\n",
    "                pid_z.Ki, pid_z.Kd = 0.08, 1.0\n",
    "\n",
    "            # Compute control actions with action saturation\n",
    "            control_x = np.clip(pid_x.compute(current_position[0]), -1, 1)\n",
    "            control_y = np.clip(pid_y.compute(current_position[1]), -1, 1)\n",
    "            control_z = np.clip(pid_z.compute(current_position[2]), -1, 1)\n",
    "            action = np.array([control_x, control_y, control_z])\n",
    "\n",
    "            # Take a step in the environment\n",
    "            try:\n",
    "                observation, _, terminated, truncated, _ = env.step(action)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Environment step failed: {e}\")\n",
    "                print(f\"Failed to take a step for {image_name}, Root Tip {idx + 1}.\")\n",
    "                break\n",
    "\n",
    "            # Track recent errors for early termination\n",
    "            recent_errors.append(error)\n",
    "            if len(recent_errors) > 20:\n",
    "                recent_errors.pop(0)\n",
    "                avg_error_change = abs(recent_errors[-1] - recent_errors[0]) / 5\n",
    "                if avg_error_change < 0.0005:\n",
    "                    logging.info(f\"Terminating early due to negligible error change after {epoch} epochs.\")\n",
    "                    print(f\"Early termination at epoch {epoch} due to negligible error change.\")\n",
    "                    break\n",
    "\n",
    "            # Handle truncation\n",
    "            if truncated:\n",
    "                logging.warning(\"Environment truncated. Resetting...\")\n",
    "                observation, info = env.reset()\n",
    "                pid_x.setpoint = target_position[0]\n",
    "                pid_y.setpoint = target_position[1]\n",
    "                pid_z.setpoint = target_position[2]\n",
    "\n",
    "        # Log final result for this root tip\n",
    "        if error > 0.005:\n",
    "            logging.warning(f\"Root Tip {idx + 1}: Failed to reach target within 200 epochs.\")\n",
    "            print(f\"Root Tip {idx + 1} failed to reach target within 200 epochs.\")\n",
    "\n",
    "logging.info(\"PID Controller Test Complete.\")\n",
    "print(\"PID Controller Test Complete. Check the log file for details.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d2e29-0db1-4d30-861e-0b60844a5e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
