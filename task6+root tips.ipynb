{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a6f00c-03db-49e6-a0b5-2f0d6dc64721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:07:30.301581: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-09 09:07:30.301623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-09 09:07:30.303069: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-09 09:07:30.310664: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from patchify import patchify, unpatchify\n",
    "from tensorflow.keras import backend as K\n",
    "from skimage.measure import label\n",
    "\n",
    "def f1(y_true, y_pred, threshold=0.3):\n",
    "    y_pred = tf.cast(y_pred > threshold, tf.float32)\n",
    "    TP = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    Positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
    "    Pred_Positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    precision = TP / (Pred_Positives + tf.keras.backend.epsilon())\n",
    "    recall = TP / (Positives + tf.keras.backend.epsilon())\n",
    "    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
    "    \n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def f1_metric(y_true, y_pred):\n",
    "    return f1(y_true, y_pred, threshold=0.3)\n",
    "\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Weighted binary cross-entropy to address class imbalance.\n",
    "    \"\"\"\n",
    "    # Define weights for foreground (root, shoot, seed) and background\n",
    "    weight_foreground = 10.0\n",
    "    weight_background = 1.0\n",
    "\n",
    "    # Compute weighted binary cross-entropy\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    weights = tf.where(y_true == 1, weight_foreground, weight_background)\n",
    "    loss = K.binary_crossentropy(y_true, y_pred)\n",
    "    weighted_loss = loss * weights\n",
    "    return K.mean(weighted_loss)\n",
    "def dice_loss(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2. * intersection + 1e-7) / (union + 1e-7)\n",
    "    return 1 - dice\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def combined_loss(y_true, y_pred):\n",
    "    return 0.5 * dice_loss(y_true, y_pred) + 0.5 * weighted_binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6fc810e-99cf-4b09-ac91-c8df749c3f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 09:07:33.620142: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-01-09 09:07:33.620528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 25223 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:25:00.0, compute capability: 8.6\n",
      "INFO: Processing image: test_image_1.png\n",
      "2025-01-09 09:07:39.390672: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "INFO: Extracted Root Tip Coordinates for test_image_1.png: [array([ 6.89359458, 43.1754469 ,  0.057     ]), array([1.65251159e+01, 6.26390207e+01, 5.70000000e-02]), array([23.2015114 , 54.59262704,  0.057     ]), array([7.61201542e+01, 3.94784552e+01, 5.70000000e-02]), array([1.25864773e+02, 4.50239427e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_10.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_10.png: [array([1.46895942e+01, 9.01801525e+01, 5.70000000e-02]), array([3.22199730e+01, 1.15905179e+02, 5.70000000e-02]), array([7.14622890e+01, 1.06990034e+02, 5.70000000e-02]), array([1.07756070e+02, 9.66785414e+01, 5.70000000e-02]), array([1.35525906e+02, 8.86763931e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_11.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_11.png: [array([4.39806105e+00, 1.05432569e+02, 5.70000000e-02]), array([3.4591125e+01, 1.1128649e+02, 5.7000000e-02]), array([6.99861912e+01, 1.04036221e+02, 5.70000000e-02]), array([1.02378040e+02, 1.13810657e+02, 5.70000000e-02]), array([1.14980828e+02, 1.10373493e+02, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_12.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_12.png: [array([2.40176857e+01, 7.67274728e+01, 5.70000000e-02]), array([4.51399158e+01, 8.04344928e+01, 5.70000000e-02]), array([7.40891653e+01, 7.16236046e+01, 5.70000000e-02]), array([9.35494941e+01, 7.35577020e+01, 5.70000000e-02]), array([1.24857571e+02, 7.45784756e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_13.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_13.png: [array([1.87639330e+01, 1.00115706e+02, 5.70000000e-02]), array([4.92678644e+01, 8.87300988e+01, 5.70000000e-02]), array([7.02828751e+01, 8.39502922e+01, 5.70000000e-02]), array([1.04539487e+02, 9.58729560e+01, 5.70000000e-02]), array([1.23785377e+02, 1.04197338e+02, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_14.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_14.png: [array([6.16781435e+00, 9.94175317e+01, 5.70000000e-02]), array([6.54321657e+00, 7.53573813e+01, 5.70000000e-02]), array([1.31605784e+02, 1.39717744e+01, 5.70000000e-02]), array([1.32678361e+02, 9.67531901e+00, 5.70000000e-02]), array([1.41098097e+02, 2.88482513e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_15.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_15.png: [array([3.16459662e+00, 1.22618391e+02, 5.70000000e-02]), array([7.88393877e+00, 1.23370271e+02, 5.70000000e-02]), array([9.81457875e+00, 7.66463179e+01, 5.70000000e-02]), array([1.96822942e+01, 9.07172095e+01, 5.70000000e-02]), array([1.47372677e+02, 1.34379938e+02, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_16.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_16.png: [array([1.39926678e+01, 1.34057704e+02, 5.70000000e-02]), array([22.30217459, 46.78595274,  0.057     ]), array([50.92976573, 46.46371858,  0.057     ]), array([1.03735341e+02, 4.94712374e+01, 5.70000000e-02]), array([1.32362932e+02, 4.70544812e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_17.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_17.png: [array([1.60298372e+01, 5.94817708e+01, 5.70000000e-02]), array([4.55151839e+01, 6.25440917e+01, 5.70000000e-02]), array([7.37675070e+01, 6.63585616e+01, 5.70000000e-02]), array([1.04968365e+02, 6.47468138e+01, 5.70000000e-02]), array([1.24482303e+02, 6.22754670e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_18.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_18.png: [array([1.38367454e+01, 1.13810657e+02, 5.70000000e-02]), array([1.63036742e+01, 5.81715596e+01, 5.70000000e-02]), array([5.05725337e+01, 8.32521182e+01, 5.70000000e-02]), array([1.06936495e+02, 9.67322470e+01, 5.70000000e-02]), array([1.34448115e+02, 9.67322470e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_2.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_2.png: [array([6.47567453e+00, 8.23916069e+01, 5.70000000e-02]), array([49.03735813, 32.8964753 ,  0.057     ]), array([6.79778516e+01, 7.23303015e+01, 5.70000000e-02]), array([1.00742728e+02, 1.01865101e+02, 5.70000000e-02]), array([1.20064209e+02, 9.04514699e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_3.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_3.png: [array([20.7785484 , 36.16406298,  0.057     ]), array([49.59735992, 29.43224973,  0.057     ]), array([7.60100468e+01, 3.14952248e+01, 5.70000000e-02]), array([1.03352373e+02, 3.36667774e+01, 5.70000000e-02]), array([1.32116500e+02, 3.15495136e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_4.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_4.png: [array([22.09756448, 44.34204331,  0.057     ]), array([50.96260631, 43.42179791,  0.057     ]), array([7.63354692e+01, 3.78461934e+01, 5.70000000e-02]), array([9.97985467e+01, 4.30970054e+01, 5.70000000e-02]), array([1.31992072e+02, 3.41110798e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_5.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_5.png: [array([21.76957874, 43.94728139,  0.057     ]), array([47.24127685, 40.91697835,  0.057     ]), array([7.45634829e+01, 3.19884069e+01, 5.70000000e-02]), array([1.01504702e+02, 3.95641645e+01, 5.70000000e-02]), array([1.33616458e+02, 3.87524762e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_6.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_6.png: [array([21.41178197, 44.70937794,  0.057     ]), array([43.47861814, 52.90105967,  0.057     ]), array([7.15389160e+01, 5.29010597e+01, 5.70000000e-02]), array([1.00307532e+02, 5.14363219e+01, 5.70000000e-02]), array([1.28749232e+02, 4.19969005e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_7.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_7.png: [array([20.96831645, 50.062     ,  0.057     ]), array([47.22103976, 37.73843865,  0.057     ]), array([7.54345474e+01, 3.22552682e+01, 5.70000000e-02]), array([1.05173109e+02, 4.96819783e+01, 5.70000000e-02]), array([1.31752630e+02, 5.38622172e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_8.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_8.png: [array([9.48275000e+00, 1.33317058e+02, 5.70000000e-02]), array([3.07400174e+01, 1.37002029e+02, 5.70000000e-02]), array([7.51622558e+01, 1.29523705e+02, 5.70000000e-02]), array([8.93337674e+01, 1.19390035e+02, 5.70000000e-02]), array([1.31139727e+02, 6.31942254e+01, 5.70000000e-02])]\n",
      "INFO: Processing image: test_image_9.png\n",
      "INFO: Extracted Root Tip Coordinates for test_image_9.png: [array([2.34815885e+01, 5.82252653e+01, 5.70000000e-02]), array([47.60596301, 55.37886359,  0.057     ]), array([7.55902375e+01, 6.20920752e+01, 5.70000000e-02]), array([1.06094169e+02, 5.09212911e+01, 5.70000000e-02]), array([1.31934055e+02, 6.07494329e+01, 5.70000000e-02])]\n",
      "INFO: All Extracted Root Tip Coordinates:\n",
      "INFO: test_image_1.png: [array([ 6.89359458, 43.1754469 ,  0.057     ]), array([1.65251159e+01, 6.26390207e+01, 5.70000000e-02]), array([23.2015114 , 54.59262704,  0.057     ]), array([7.61201542e+01, 3.94784552e+01, 5.70000000e-02]), array([1.25864773e+02, 4.50239427e+01, 5.70000000e-02])]\n",
      "INFO: test_image_10.png: [array([1.46895942e+01, 9.01801525e+01, 5.70000000e-02]), array([3.22199730e+01, 1.15905179e+02, 5.70000000e-02]), array([7.14622890e+01, 1.06990034e+02, 5.70000000e-02]), array([1.07756070e+02, 9.66785414e+01, 5.70000000e-02]), array([1.35525906e+02, 8.86763931e+01, 5.70000000e-02])]\n",
      "INFO: test_image_11.png: [array([4.39806105e+00, 1.05432569e+02, 5.70000000e-02]), array([3.4591125e+01, 1.1128649e+02, 5.7000000e-02]), array([6.99861912e+01, 1.04036221e+02, 5.70000000e-02]), array([1.02378040e+02, 1.13810657e+02, 5.70000000e-02]), array([1.14980828e+02, 1.10373493e+02, 5.70000000e-02])]\n",
      "INFO: test_image_12.png: [array([2.40176857e+01, 7.67274728e+01, 5.70000000e-02]), array([4.51399158e+01, 8.04344928e+01, 5.70000000e-02]), array([7.40891653e+01, 7.16236046e+01, 5.70000000e-02]), array([9.35494941e+01, 7.35577020e+01, 5.70000000e-02]), array([1.24857571e+02, 7.45784756e+01, 5.70000000e-02])]\n",
      "INFO: test_image_13.png: [array([1.87639330e+01, 1.00115706e+02, 5.70000000e-02]), array([4.92678644e+01, 8.87300988e+01, 5.70000000e-02]), array([7.02828751e+01, 8.39502922e+01, 5.70000000e-02]), array([1.04539487e+02, 9.58729560e+01, 5.70000000e-02]), array([1.23785377e+02, 1.04197338e+02, 5.70000000e-02])]\n",
      "INFO: test_image_14.png: [array([6.16781435e+00, 9.94175317e+01, 5.70000000e-02]), array([6.54321657e+00, 7.53573813e+01, 5.70000000e-02]), array([1.31605784e+02, 1.39717744e+01, 5.70000000e-02]), array([1.32678361e+02, 9.67531901e+00, 5.70000000e-02]), array([1.41098097e+02, 2.88482513e+01, 5.70000000e-02])]\n",
      "INFO: test_image_15.png: [array([3.16459662e+00, 1.22618391e+02, 5.70000000e-02]), array([7.88393877e+00, 1.23370271e+02, 5.70000000e-02]), array([9.81457875e+00, 7.66463179e+01, 5.70000000e-02]), array([1.96822942e+01, 9.07172095e+01, 5.70000000e-02]), array([1.47372677e+02, 1.34379938e+02, 5.70000000e-02])]\n",
      "INFO: test_image_16.png: [array([1.39926678e+01, 1.34057704e+02, 5.70000000e-02]), array([22.30217459, 46.78595274,  0.057     ]), array([50.92976573, 46.46371858,  0.057     ]), array([1.03735341e+02, 4.94712374e+01, 5.70000000e-02]), array([1.32362932e+02, 4.70544812e+01, 5.70000000e-02])]\n",
      "INFO: test_image_17.png: [array([1.60298372e+01, 5.94817708e+01, 5.70000000e-02]), array([4.55151839e+01, 6.25440917e+01, 5.70000000e-02]), array([7.37675070e+01, 6.63585616e+01, 5.70000000e-02]), array([1.04968365e+02, 6.47468138e+01, 5.70000000e-02]), array([1.24482303e+02, 6.22754670e+01, 5.70000000e-02])]\n",
      "INFO: test_image_18.png: [array([1.38367454e+01, 1.13810657e+02, 5.70000000e-02]), array([1.63036742e+01, 5.81715596e+01, 5.70000000e-02]), array([5.05725337e+01, 8.32521182e+01, 5.70000000e-02]), array([1.06936495e+02, 9.67322470e+01, 5.70000000e-02]), array([1.34448115e+02, 9.67322470e+01, 5.70000000e-02])]\n",
      "INFO: test_image_2.png: [array([6.47567453e+00, 8.23916069e+01, 5.70000000e-02]), array([49.03735813, 32.8964753 ,  0.057     ]), array([6.79778516e+01, 7.23303015e+01, 5.70000000e-02]), array([1.00742728e+02, 1.01865101e+02, 5.70000000e-02]), array([1.20064209e+02, 9.04514699e+01, 5.70000000e-02])]\n",
      "INFO: test_image_3.png: [array([20.7785484 , 36.16406298,  0.057     ]), array([49.59735992, 29.43224973,  0.057     ]), array([7.60100468e+01, 3.14952248e+01, 5.70000000e-02]), array([1.03352373e+02, 3.36667774e+01, 5.70000000e-02]), array([1.32116500e+02, 3.15495136e+01, 5.70000000e-02])]\n",
      "INFO: test_image_4.png: [array([22.09756448, 44.34204331,  0.057     ]), array([50.96260631, 43.42179791,  0.057     ]), array([7.63354692e+01, 3.78461934e+01, 5.70000000e-02]), array([9.97985467e+01, 4.30970054e+01, 5.70000000e-02]), array([1.31992072e+02, 3.41110798e+01, 5.70000000e-02])]\n",
      "INFO: test_image_5.png: [array([21.76957874, 43.94728139,  0.057     ]), array([47.24127685, 40.91697835,  0.057     ]), array([7.45634829e+01, 3.19884069e+01, 5.70000000e-02]), array([1.01504702e+02, 3.95641645e+01, 5.70000000e-02]), array([1.33616458e+02, 3.87524762e+01, 5.70000000e-02])]\n",
      "INFO: test_image_6.png: [array([21.41178197, 44.70937794,  0.057     ]), array([43.47861814, 52.90105967,  0.057     ]), array([7.15389160e+01, 5.29010597e+01, 5.70000000e-02]), array([1.00307532e+02, 5.14363219e+01, 5.70000000e-02]), array([1.28749232e+02, 4.19969005e+01, 5.70000000e-02])]\n",
      "INFO: test_image_7.png: [array([20.96831645, 50.062     ,  0.057     ]), array([47.22103976, 37.73843865,  0.057     ]), array([7.54345474e+01, 3.22552682e+01, 5.70000000e-02]), array([1.05173109e+02, 4.96819783e+01, 5.70000000e-02]), array([1.31752630e+02, 5.38622172e+01, 5.70000000e-02])]\n",
      "INFO: test_image_8.png: [array([9.48275000e+00, 1.33317058e+02, 5.70000000e-02]), array([3.07400174e+01, 1.37002029e+02, 5.70000000e-02]), array([7.51622558e+01, 1.29523705e+02, 5.70000000e-02]), array([8.93337674e+01, 1.19390035e+02, 5.70000000e-02]), array([1.31139727e+02, 6.31942254e+01, 5.70000000e-02])]\n",
      "INFO: test_image_9.png: [array([2.34815885e+01, 5.82252653e+01, 5.70000000e-02]), array([47.60596301, 55.37886359,  0.057     ]), array([7.55902375e+01, 6.20920752e+01, 5.70000000e-02]), array([1.06094169e+02, 5.09212911e+01, 5.70000000e-02]), array([1.31934055e+02, 6.07494329e+01, 5.70000000e-02])]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"pipeline_log.txt\"), logging.StreamHandler()],\n",
    ")\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess the input image.\"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    return image\n",
    "\n",
    "def extract_petri_dish(image):\n",
    "    \"\"\"Extract the largest contour assumed to be the Petri dish.\"\"\"\n",
    "    _, thresholded = cv2.threshold(image, 57, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        logging.warning(\"No contours detected for Petri dish.\")\n",
    "        return image, np.ones_like(image)\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    return cropped_image\n",
    "\n",
    "def predict_root_mask(image, model, patch_size=128, stride=64):\n",
    "    \"\"\"Predict root mask using a patch-based model.\"\"\"\n",
    "    h, w = image.shape\n",
    "    patches = []\n",
    "    positions = []\n",
    "    for y in range(0, h - patch_size + 1, stride):\n",
    "        for x in range(0, w - patch_size + 1, stride):\n",
    "            patch = image[y:y+patch_size, x:x+patch_size]\n",
    "            patch_rgb = np.stack([patch]*3, axis=-1)\n",
    "            patches.append(patch_rgb)\n",
    "            positions.append((y, x))\n",
    "\n",
    "    patches = np.array(patches) / 255.0\n",
    "    predictions = model.predict(patches, verbose=0)\n",
    "\n",
    "    reconstructed = np.zeros((h, w), dtype=np.float32)\n",
    "    counts = np.zeros((h, w), dtype=np.float32)\n",
    "    for pred, (y, x) in zip(predictions, positions):\n",
    "        pred = pred[..., 0]\n",
    "        reconstructed[y:y+patch_size, x:x+patch_size] += pred\n",
    "        counts[y:y+patch_size, x:x+patch_size] += 1\n",
    "    return (reconstructed / np.maximum(counts, 1) > 0.3).astype(np.uint8)\n",
    "\n",
    "def connect_roots(mask):\n",
    "    \"\"\"Dilate the mask to connect fragmented roots.\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "    return cv2.dilate(mask, kernel, iterations=27)\n",
    "\n",
    "def filter_and_select_largest_objects(mask, min_area=500, max_objects=5):\n",
    "    \"\"\"Filter and retain the largest root components.\"\"\"\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    valid_objects = [(i, stats[i, cv2.CC_STAT_AREA]) for i in range(1, num_labels) if stats[i, cv2.CC_STAT_AREA] >= min_area]\n",
    "    largest_objects = sorted(valid_objects, key=lambda x: x[1], reverse=True)[:max_objects]\n",
    "\n",
    "    filtered_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for obj_id, _ in largest_objects:\n",
    "        filtered_mask[labels == obj_id] = 255\n",
    "    return filtered_mask, largest_objects\n",
    "\n",
    "def measure_bounding_boxes(filtered_mask):\n",
    "    \"\"\"Measure roots with bounding boxes.\"\"\"\n",
    "    contours, _ = cv2.findContours(filtered_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    bounding_boxes = sorted(bounding_boxes, key=lambda b: b[0])\n",
    "    return bounding_boxes\n",
    "\n",
    "def find_lowest_point(mask, bounding_box):\n",
    "    \"\"\"Find the lowest point in a bounding box.\"\"\"\n",
    "    x, y, w, h = bounding_box\n",
    "    roi = mask[y:y+h, x:x+w]\n",
    "    coordinates = np.column_stack(np.where(roi > 0))\n",
    "    if len(coordinates) == 0:\n",
    "        return None\n",
    "    lowest_local = coordinates[np.argmax(coordinates[:, 0])]\n",
    "    return lowest_local + [y, x]\n",
    "\n",
    "def convert_to_mm(pixel_coords, image_shape, plate_size_mm=150):\n",
    "    \"\"\"Convert pixel coordinates to mm-space.\"\"\"\n",
    "    h, w = image_shape\n",
    "    conversion_factor_x = plate_size_mm / w\n",
    "    conversion_factor_y = plate_size_mm / h\n",
    "    return np.array([pixel_coords[1] * conversion_factor_x, pixel_coords[0] * conversion_factor_y])\n",
    "\n",
    "# Directory containing images\n",
    "input_dir = \"kaggle_test\"\n",
    "model_path = \"232430_unet_model_128px_v7md.keras\"\n",
    "plate_position_robot = np.array([0.10775, 0.088 - 0.026, 0.057])  # Adjust based on your setup\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Process all images in the directory\n",
    "all_root_tip_coords = {}\n",
    "\n",
    "for image_name in sorted(os.listdir(input_dir)):\n",
    "    if not image_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(input_dir, image_name)\n",
    "    logging.info(f\"Processing image: {image_name}\")\n",
    "\n",
    "    try:\n",
    "        # Process the image and extract root tip coordinates\n",
    "        image = preprocess_image(image_path)\n",
    "        petri_dish = extract_petri_dish(image)\n",
    "        predicted_mask = predict_root_mask(petri_dish, model)\n",
    "        connected_mask = connect_roots(predicted_mask)\n",
    "        filtered_mask, _ = filter_and_select_largest_objects(connected_mask, min_area=500, max_objects=5)\n",
    "        bounding_boxes = measure_bounding_boxes(filtered_mask)\n",
    "\n",
    "        root_tip_coords = []\n",
    "        for box in bounding_boxes:\n",
    "            point = find_lowest_point(filtered_mask, box)\n",
    "            if point is not None:\n",
    "                mm_coords = convert_to_mm(point, petri_dish.shape)\n",
    "                robot_coords = np.append(mm_coords, 0) + plate_position_robot\n",
    "                root_tip_coords.append(robot_coords)\n",
    "\n",
    "        all_root_tip_coords[image_name] = root_tip_coords\n",
    "        logging.info(f\"Extracted Root Tip Coordinates for {image_name}: {root_tip_coords}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing image {image_name}: {e}\")\n",
    "\n",
    "# Expose all_root_tip_coords for import\n",
    "def get_root_tip_coords():\n",
    "    return all_root_tip_coords\n",
    "\n",
    "# Log all extracted root tip coordinates\n",
    "logging.info(\"All Extracted Root Tip Coordinates:\")\n",
    "for img_name, coords in all_root_tip_coords.items():\n",
    "    logging.info(f\"{img_name}: {coords}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6b934e-0822-4762-8ed6-f50deab651a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pid_controller'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msim_class\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Simulation\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get the directory of the current script\u001b[39;00m\n",
      "File \u001b[0;32m/home/y2b/renforcement_learning_232430/sim_class.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpid_controller\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PIDController  \u001b[38;5;66;03m# Import PIDController\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSimulation\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_agents, render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rgb_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pid_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pid_controller'"
     ]
    }
   ],
   "source": [
    "from sim_class import Simulation\n",
    "import os\n",
    "from pid_class import PIDController\n",
    "\n",
    "\n",
    "# Get the directory of the current script\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Change the current working directory to the script's directory\n",
    "os.chdir(script_dir)\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Initialize simulation with one agent\n",
    "num_agents = 1\n",
    "simulation = Simulation(num_agents=num_agents, render=True)\n",
    "\n",
    "# Define custom PID parameters for each robot (optional)\n",
    "custom_pid_params = [\n",
    "    {'x': {'Kp': 2.0, 'Ki': 0.1, 'Kd': 0.05}, 'y': {'Kp': 2.0, 'Ki': 0.1, 'Kd': 0.05}, 'z': {'Kp': 3.0, 'Ki': 0.2, 'Kd': 0.1}}\n",
    "]\n",
    "\n",
    "# Set PID parameters (optional, otherwise uses defaults in Simulation)\n",
    "simulation.set_pid_params(custom_pid_params)\n",
    "\n",
    "# Define the target positions for each robot\n",
    "setpoints = all_root_tip_coords\n",
    "simulation.set_pid_setpoints(setpoints)\n",
    "\n",
    "# Run the simulation loop\n",
    "try:\n",
    "    num_steps = 2400  # Number of simulation steps\n",
    "    for step in range(num_steps):\n",
    "        simulation.control_pid()  # Update velocities based on PID control\n",
    "        p.stepSimulation()  # Step the simulation\n",
    "\n",
    "        # Optional: Slow down the simulation for better visualization\n",
    "        time.sleep(1.0 / 240.0)\n",
    "\n",
    "        # Optional: Print pipette positions for debugging\n",
    "        if step % 100 == 0:\n",
    "            states = simulation.get_states()\n",
    "            print(f\"Step {step}: {states}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Simulation interrupted.\")\n",
    "\n",
    "finally:\n",
    "    simulation.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d2e29-0db1-4d30-861e-0b60844a5e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ade728-1bf1-4402-9e52-d3922dd29e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
